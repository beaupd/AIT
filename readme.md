# Local Structured AI Coding Assistant

A **local-first, structured AI coding assistant** designed to work reliably with **small, openâ€‘source LLMs** by eliminating guesswork, minimizing hallucinations, and enforcing explicit project understanding.

This project is **not a chat-based code generator**. It is a toolchain that builds and maintains a _project intelligence layer_ and uses LLMs as constrained, taskâ€‘specific functions.

---

## âœ¨ Core Idea

Large models compensate for lack of structure with scale. This project takes the opposite approach:

> **Structure + persistence + narrow objectives â†’ reliable AI behavior**

Instead of giving a model your entire repository and hoping for the best, we:

- Maintain a local database that _understands_ the codebase
- Explicitly track files, symbols, relationships, and standards
- Route only the minimum necessary context to small LLMs
- Split work into deterministic, singleâ€‘purpose agents

The result is faster, cheaper, more predictable AI assistance that works locally.

---

## ðŸŽ¯ Goals

- Work with **small (3Bâ€“7B) openâ€‘source models**
- Reduce hallucinations by design, not by luck
- Persist project knowledge across sessions
- Be transparent, inspectable, and debuggable
- Integrate naturally into existing developer workflows

Initial target platform: **VS Code extension backed by a local service**.

---

## ðŸ§  Highâ€‘Level Architecture

```
VS Code Extension
       â”‚
       â–¼
Local AI Service (daemon)
       â”‚
       â”œâ”€â”€ Project Indexer
       â”œâ”€â”€ Context Router
       â”œâ”€â”€ Agent Executor
       â””â”€â”€ Project Intelligence DB (SQLite)
               â”œâ”€â”€ Relational metadata
               â””â”€â”€ Vector embeddings
```

The editor provides UI and intent. The local service does the reasoning.

---

## ðŸ—„ï¸ Project Intelligence Database

The system is built around a **local SQLite database** that acts as the authoritative memory of the project.

### Why SQLite?

- Zero configuration
- Fast and local
- Easy to inspect and debug
- Sufficient for perâ€‘project intelligence

### Dual Representation

The database stores information in two complementary forms:

1. **Structured relational data** (authoritative)
2. **Vector embeddings** (assistive, retrievalâ€‘only)

Vectors are never trusted on their own. They only help locate relevant entities.

---

## ðŸ“ Core Tables (Conceptual)

### `files`

Stores fileâ€‘level metadata.

- Path and language
- Role (core, test, config, etc.)
- Short factual summary
- Stability (stable / experimental)

### `symbols`

Tracks important code symbols.

- Functions, classes, constants
- Visibility and ownership
- Purpose summaries

### `relations`

Explicit relationships between files and symbols.

- Imports
- Calls
- Mirrors / parallels

### `standards`

Projectâ€‘specific rules and conventions.

- Naming
- Error handling
- Logging
- Architectural patterns

### `embeddings`

Vector representations of files, symbols, and standards for semantic lookup.

---

## ðŸ”„ Indexing Pipeline

The indexer runs when:

- A project is opened
- Files are saved
- Manual reindexing is triggered

### Indexing Steps

1. Parse file structure
2. Extract symbols
3. Generate **short, factual summaries**
4. Store metadata in SQLite
5. Generate embeddings (optional but recommended)

LLMs used here are limited to summarization and classification â€” no code generation.

---

## ðŸ¤– Agentâ€‘Based Execution Model

There is **no general chat agent**.

All functionality is implemented as **taskâ€‘specific agents**, each with:

- A single responsibility
- Explicit inputs
- Explicit outputs
- Strict context limits

### Example Agents

| Agent            | Responsibility                    |
| ---------------- | --------------------------------- |
| File Finder      | Select relevant files             |
| Standards Loader | Retrieve applicable rules         |
| Change Planner   | Decide what should change         |
| Diff Generator   | Produce code diffs                |
| Validator        | Check correctness and consistency |

Agents do not explore the codebase. They operate only on provided context.

---

## ðŸ§­ Context Routing

When a user issues a command (e.g. _â€œrefactor this functionâ€_):

1. Identify the task type
2. Select required agents
3. Query the database for:

   - Relevant files
   - Related symbols
   - Applicable standards

4. Assemble **minimal context**
5. Execute agents in sequence
6. Validate results before applying changes

No agent ever sees the entire repository.

---

## ðŸ§© VS Code Extension Role

The extension is intentionally thin. It:

- Captures user intent
- Displays explanations and diffs
- Applies changes safely
- Communicates with the local service

### Example Commands

- Explain this file
- Refactor this function safely
- Why does this test fail?
- Summarize project conventions

All intelligence lives outside the editor.

---

## ðŸ§  LLM Usage Philosophy

LLMs are treated as **pure functions**, not autonomous agents.

Rules:

- Small prompts
- Explicit instructions
- No hidden context
- No internal memory

All longâ€‘term memory lives in the database.

---

## ðŸš« Hallucination Mitigation (By Design)

Hallucinations are reduced by:

- Explicit context selection
- Persistent project knowledge
- Clear task boundaries
- Deterministic agent roles

If the system lacks sufficient information, it **refuses the task** instead of guessing.

---

## ðŸ§ª Model Strategy

- Fully openâ€‘source models
- Different models for different tasks
- Separate embedding and generation models

The system is **modelâ€‘agnostic**. Models are replaceable.

---

## ðŸ§° Interfaces

- **VS Code Extension** (primary)
- **Zed Extension** (Rust-based, WebAssembly)
- **CLI** for power users and automation
- Future: LSPâ€‘style integration for other editors

---

## ðŸ—ºï¸ Roadmap

### Phase 1

- Local daemon
- SQLite project intelligence DB
- VS Code extension
- CLI interface

### Phase 2

- Teamâ€‘shared standards
- Policy enforcement
- Enterprise features
- Optional hosted inference

---

## ðŸ”‘ Guiding Principle

> **The system understands the project â€” not the model.**

The database is the product. The LLM is an interchangeable component.

---

## ðŸ“œ License & Philosophy

This project is designed to be:

- Open
- Localâ€‘first
- Transparent
- Developerâ€‘controlled

AI should behave like tooling, not magic.
